{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnn.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"mnDn_dVLiQ9y","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B6gHSUMwjsGQ","colab_type":"code","colab":{}},"cell_type":"code","source":["SOS_token = 0\n","EOS_token = 1\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jZciPJE8jwRE","colab_type":"code","colab":{}},"cell_type":"code","source":["def readLangs(lang1, lang2):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines1 = open('%s.txt' % lang1, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    \n","    # Read the file and split into lines\n","    lines2 = open('%s.txt' % lang2, encoding='utf-8').\\\n","        read().strip().split('\\n')\n","    \n","\n","    # Split every line into pairs and normalize\n","    pairs = []\n","    for i in range(len(lines1)):\n","        pairs.append([lines1[i],lines2[i]])\n","\n","    input_lang = Lang(lang1)\n","    output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6AO5ABo3ylB9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"outputId":"4ddd65f7-8507-4b92-d83c-dbba4d02fe95","executionInfo":{"status":"ok","timestamp":1556234416529,"user_tz":240,"elapsed":411,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["def prepareData(lang1, lang2):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('file1', 'file2')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Read 625 sentence pairs\n","Counting words...\n","Counted words:\n","file1 59\n","file2 4\n"],"name":"stdout"}]},{"metadata":{"id":"ZGLgOVNzy8TF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e6b35760-3f2d-45ed-e663-5868aa80a2f7","executionInfo":{"status":"ok","timestamp":1556234426473,"user_tz":240,"elapsed":219,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["print(random.choice(pairs))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['does a rose have skin ?', 'no']\n"],"name":"stdout"}]},{"metadata":{"id":"QMK6IC1dzNam","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1089},"outputId":"7f01d040-5b54-41c7-c45b-92294b1c75d6","executionInfo":{"status":"ok","timestamp":1556234534725,"user_tz":240,"elapsed":327,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["input_lang.index2word"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'SOS',\n"," 1: 'EOS',\n"," 2: 'is',\n"," 3: 'a',\n"," 4: 'beaver',\n"," 5: 'pretty',\n"," 6: '?',\n"," 7: 'an',\n"," 8: 'otter',\n"," 9: 'dolphin',\n"," 10: 'trout',\n"," 11: 'flatfish',\n"," 12: 'shark',\n"," 13: 'bear',\n"," 14: 'wolf',\n"," 15: 'tiger',\n"," 16: 'fox',\n"," 17: 'rabbit',\n"," 18: 'crocodile',\n"," 19: 'snake',\n"," 20: 'bee',\n"," 21: 'butterfly',\n"," 22: 'maple_tree',\n"," 23: 'oak_tree',\n"," 24: 'palm_tree',\n"," 25: 'pine_tree',\n"," 26: 'willow_tree',\n"," 27: 'orchid',\n"," 28: 'poppy',\n"," 29: 'tulip',\n"," 30: 'sunflower',\n"," 31: 'rose',\n"," 32: 'big',\n"," 33: 'living',\n"," 34: 'green',\n"," 35: 'red',\n"," 36: 'yellow',\n"," 37: 'white',\n"," 38: 'can',\n"," 39: 'grow',\n"," 40: 'move',\n"," 41: 'swim',\n"," 42: 'fly',\n"," 43: 'walk',\n"," 44: 'growl',\n"," 45: 'does',\n"," 46: 'have',\n"," 47: 'leaves',\n"," 48: 'roots',\n"," 49: 'skin',\n"," 50: 'legs',\n"," 51: 'bark',\n"," 52: 'branches',\n"," 53: 'petals',\n"," 54: 'wings',\n"," 55: 'feathers',\n"," 56: 'scales',\n"," 57: 'gills',\n"," 58: 'fur'}"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"zAorIkQMzn07","colab_type":"code","colab":{}},"cell_type":"code","source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CZza6xFBzybG","colab_type":"code","colab":{}},"cell_type":"code","source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D6_-cDa-z18C","colab_type":"code","colab":{}},"cell_type":"code","source":["MAX_LENGTH = 10\n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MC6JrwCmz64K","colab_type":"code","colab":{}},"cell_type":"code","source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"imYNfta90D13","colab_type":"code","colab":{}},"cell_type":"code","source":["teacher_forcing_ratio = 0.5\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GgUwUHvH0FJ5","colab_type":"code","colab":{}},"cell_type":"code","source":["import time\n","import math\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cgYQoQto0Iic","colab_type":"code","colab":{}},"cell_type":"code","source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T5ELASYh0MNp","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U_WAvUtF0PoS","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mHCBD-mh0TyD","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluate(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Io9x3xnY0Wwe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"aec9ddc4-6fc4-4cf9-f169-06b7100cbedd","executionInfo":{"status":"ok","timestamp":1556236044741,"user_tz":240,"elapsed":78032,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["hidden_size = 128\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 10000, print_every=5000)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["0m 39s (- 0m 39s) (5000 50%) 0.2678\n","1m 17s (- 0m 0s) (10000 100%) 0.1729\n"],"name":"stdout"}]},{"metadata":{"id":"THtfo1W70o8P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":744},"outputId":"81441146-b803-4af9-9fdb-3141db97d260","executionInfo":{"status":"ok","timestamp":1556236151861,"user_tz":240,"elapsed":287,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["evaluateRandomly(encoder1, attn_decoder1)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["> is a rabbit red ?\n","= no\n","< no <EOS>\n","\n","> does a willow_tree have fur ?\n","= no\n","< no <EOS>\n","\n","> does a shark have wings ?\n","= no\n","< no <EOS>\n","\n","> can a rabbit move ?\n","= yes\n","< yes <EOS>\n","\n","> does a sunflower have feathers ?\n","= no\n","< no <EOS>\n","\n","> is a maple_tree living ?\n","= yes\n","< yes <EOS>\n","\n","> does an orchid have fur ?\n","= no\n","< no <EOS>\n","\n","> does an orchid have skin ?\n","= no\n","< no <EOS>\n","\n","> is a tiger green ?\n","= no\n","< no <EOS>\n","\n","> is a sunflower pretty ?\n","= yes\n","< no <EOS>\n","\n"],"name":"stdout"}]},{"metadata":{"id":"QiTwjcYM0zAo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"720771f9-1c0a-4c6d-cb73-0cf3daab18f3","executionInfo":{"status":"ok","timestamp":1556235721793,"user_tz":240,"elapsed":546,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["output_words, attentions = evaluate(\n","    encoder1, attn_decoder1, \"can a dolphin fly ?\")\n","plt.matshow(attentions.numpy())"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fe5fb4da940>"]},"metadata":{"tags":[]},"execution_count":33}]},{"metadata":{"id":"q0tyXCoMLnhX","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"8046-2IH2OEN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":162},"outputId":"9e46b990-6698-4c7f-b308-c47a93a73dbc","executionInfo":{"status":"ok","timestamp":1556235839690,"user_tz":240,"elapsed":709,"user":{"displayName":"Arihant Jain","photoUrl":"https://lh5.googleusercontent.com/-3kii2uSyBNA/AAAAAAAAAAI/AAAAAAAAHwU/T3ZvQABdreo/s64/photo.jpg","userId":"03591714780569092811"}}},"cell_type":"code","source":["def showAttention(input_sentence, output_words, attentions):\n","    # Set up figure with colorbar\n","    fig = plt.figure()\n","    ax = fig.add_subplot(111)\n","    cax = ax.matshow(attentions.numpy(), cmap='bone')\n","    fig.colorbar(cax)\n","\n","    # Set up axes\n","    ax.set_xticklabels([''] + input_sentence.split(' ') +\n","                       ['<EOS>'], rotation=90)\n","    ax.set_yticklabels([''] + output_words)\n","\n","    # Show label at every tick\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","\n","\n","def evaluateAndShowAttention(input_sentence):\n","    output_words, attentions = evaluate(\n","        encoder1, attn_decoder1, input_sentence)\n","    print('input =', input_sentence)\n","    print('output =', ' '.join(output_words))\n","    showAttention(input_sentence, output_words, attentions)\n","\n","\n","evaluateAndShowAttention(\"is a dolphin pretty ?\")\n","\n","evaluateAndShowAttention(\"is a otter white ?\")\n","\n","evaluateAndShowAttention(\"does a poppy have fur ?\")\n","\n","evaluateAndShowAttention(\"can a butterfly walk ?\")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["input = is a dolphin pretty ?\n","output = yes <EOS>\n","input = is a otter white ?\n","output = no <EOS>\n","input = does a poppy have red ?\n","output = yes <EOS>\n","input = can a butterfly walk ?\n","output = no <EOS>\n"],"name":"stdout"}]},{"metadata":{"id":"Nelvrjeb3y_W","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}